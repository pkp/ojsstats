{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import re\n",
    "import os\n",
    "import urllib\n",
    "import requests\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from oaipmh.client import Client\n",
    "from oaipmh.metadata import MetadataRegistry, oai_dc_reader\n",
    "from oaipmh.error import NoRecordsMatchError\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import pycountry\n",
    "from tld import get_tld\n",
    "import geoip2.database\n",
    "import socket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_oai_endpoint(url):\n",
    "    ''' Finds an OAI endpoint given a base OJS-install URL '''    \n",
    "    url = url.strip(\"/\")\n",
    "    verb_param = {'verb': 'Identify'}\n",
    "    urls_to_try = []  # all the combinations of possible OAI URLs, given the base url\n",
    "    urls_to_try.append(url + \"/index.php/index/oai\")\n",
    "    urls_to_try.append(url + \"/index/oai\")\n",
    "    urls_to_try.append(url + \"/index.php?page=oai\")\n",
    "    urls_to_try.append(url + \"?page=oai\")\n",
    "\n",
    "    for url_to_try in urls_to_try:\n",
    "        try:\n",
    "            request = requests.get(url_to_try, params=verb_param)\n",
    "            if request.status_code == 200 and request.headers['Content-Type'].startswith('text/xml'): \n",
    "                # take out the verb parameter before returning\n",
    "                return request.url.replace('verb=Identify', '').strip('&?')\n",
    "        except:\n",
    "            continue # move on to next URL\n",
    "            \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "oai_registry = MetadataRegistry()\n",
    "oai_registry.registerReader('oai_dc', oai_dc_reader)\n",
    "\n",
    "# Use this to determine if the OAI URL is valid. If this returns False, do not include it on our list\n",
    "def get_oai_identity(oai_url):\n",
    "    ''' Finds an OAI repository identity given an OAI URL '''\n",
    "    try:\n",
    "        client = Client(oai_url, oai_registry)\n",
    "        identity = client.identify()\n",
    "        return identity\n",
    "    except Exception as err:\n",
    "        if err.code in [404, 500]: # Might need to expand this list? \n",
    "            print(err)\n",
    "        # some other error, but probably still OK to ignore?\n",
    "        raise \n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_stop_words = ['islands', 'saint', 'and', 'republic', 'virgin', 'united', 'south', 'of', 'new', 'the']\n",
    "\n",
    "nationality_prefixes = {}\n",
    "for country in pycountry.countries:\n",
    "    nat = [x for x in re.split('[^\\w\\ \\&]', country.name) if x not in country_stop_words][0].strip(' s').strip('aeiou')\n",
    "    # a few that get confused\n",
    "    if nat == 'Austr':\n",
    "        nat = 'Austria'\n",
    "    elif nat == 'Austral':\n",
    "        nat = 'Australia'\n",
    "\n",
    "    if len(nat) > 4:\n",
    "        nationality_prefixes[nat] = country.alpha_2\n",
    "\n",
    "def get_country_from_name(journal_name):\n",
    "    matches = []\n",
    "    try: \n",
    "        for nat in nationality_prefixes.keys():\n",
    "#             print(nat.lower())\n",
    "            if journal_name.lower().find(nat.lower()) >= 0:\n",
    "                matches.append(nat)\n",
    "        longest_match = max(matches, key=len)\n",
    "        return nationality_prefixes[longest_match].upper()\n",
    "#         return pycountry.countries.get(alpha_2=nationality_prefixes[longest_match])\n",
    "    except: \n",
    "        pass\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_country_from_tld(url):\n",
    "    try:\n",
    "        tld = get_tld(url)\n",
    "        \n",
    "        # special handling for the JOLS\n",
    "        if tld == 'info':\n",
    "            if 'vjol' in url:\n",
    "                return 'VN'\n",
    "            elif 'banglajol' in url:\n",
    "                return 'BD'\n",
    "            elif 'ajol' in url:\n",
    "                return 'ZA'\n",
    "            elif 'nepjol' in url:\n",
    "                return 'NP'\n",
    "            elif 'philjol' in url:\n",
    "                return 'PH'\n",
    "            elif 'mongoliajol' in url:\n",
    "                return 'MN'\n",
    "            elif 'lamjol' in url: # need to figure out what to do with these\n",
    "                pass       \n",
    "        elif tld == 'uk':\n",
    "            return 'GB'\n",
    "        elif tld == 'edu':\n",
    "            return 'US'\n",
    "        else:\n",
    "            return tld.upper()\n",
    "#         return pycountry.countries.get(alpha_2=tld)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoIpReader = geoip2.database.Reader('data/GeoLite2-Country/GeoLite2-Country.mmdb')\n",
    "\n",
    "def get_country_from_domain(url):\n",
    "    global geoIpReader\n",
    "    try: \n",
    "        domain = urllib.parse.urlparse(url).netloc\n",
    "        ip = socket.gethostbyname(domain)\n",
    "        alpha_2 = geoIpReader.country(ip).country.iso_code\n",
    "        return alpha_2.upper()\n",
    "#         return pycountry.countries.get(alpha_2=alpha_2)\n",
    "    except: # probably should catch different exceptions from parsing, IP lookup, and geoIP Lookup\n",
    "        raise\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://ajol.info'\n",
    "oai_url = find_oai_endpoint(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "oai_registry = MetadataRegistry()\n",
    "oai_registry.registerReader('oai_dc', oai_dc_reader)\n",
    "\n",
    "client = Client(oai_url, oai_registry)\n",
    "journalSets = [(j, n) for (j,n,x) in client.listSets() if ':' not in j] # journalInitial, journalName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_from_tld = get_country_from_tld(oai_url)\n",
    "country_from_domain = get_country_from_domain(oai_url)\n",
    "\n",
    "for journal_init, journal_name in journalSets: \n",
    "    break\n",
    "    try:\n",
    "        year = 2019\n",
    "        ids = client.listIdentifiers(metadataPrefix='oai_dc', set=journal_init, from_=datetime(year,1,1), until=datetime(year,12,31))\n",
    "        ids = list(ids)\n",
    "        num_records = len([i for i in ids if ~i.isDeleted()])\n",
    "        \n",
    "        country_from_name = get_country_from_name(journal_name)\n",
    "        print(oai_url, journal_init, journal_name, year, num_records, country_from_tld, country_from_domain, country_from_name)\n",
    "    except NoRecordsMatchError:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
